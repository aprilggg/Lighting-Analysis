{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import os\n",
    "import re\n",
    "import polars as pl\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from io import BytesIO\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a `token.pickle` file already exists before running the following code. If the file exists, it is recommended to delete it and regenerate one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=389849867563-4uggnm57nqe52156v32gj1lkosoqpoem.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A37635%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=GyfvJGpr2mtpuRzI6AP8xi3h1k3QIH&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "# Scopes for accessing Google Drive\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# Authenticate and create the service object\n",
    "def authenticate_drive_api():\n",
    "    creds = None\n",
    "    # Token file for saving the authentication\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no credentials, perform authentication\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'client_secrets.json', SCOPES)  # Ensure 'credentials.json' is downloaded from Google API Console\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for future use\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# Initialize the service object\n",
    "service = authenticate_drive_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function grabs the list of all files in a specified folder that are not trashed and stores them into a list. Each file has an ID and name attribute that we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(folder_id):\n",
    "    # Query to find files in the specified folder\n",
    "    query = f\"'{folder_id}' in parents and trashed=false\"\n",
    "    files = []\n",
    "\n",
    "    # List files in the folder and append to list\n",
    "    page_token = None\n",
    "    while True:\n",
    "        response = service.files().list(\n",
    "            q=query,\n",
    "            spaces='drive',\n",
    "            fields='nextPageToken, files(id, name)',\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        files += response.get('files', [])\n",
    "\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "        if page_token is None:\n",
    "            break\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to find files for the specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the folder\n",
    "folder_id = '14idmMBbM5xXZg4b61iINHbBTl2z4yLeD'\n",
    "files = find_files(folder_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file to add cyclone id\n",
    "\n",
    "# Directory to save the processed files locally\n",
    "output_dir = \"processed_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    file_id = file['id']\n",
    "    file_name = file['name']\n",
    "\n",
    "    # Extract the cyclone ID and name from the filename\n",
    "    cyclone_id = '_'.join(file_name.split('_')[:3])\n",
    "    cyclone_name = file_name.split('_')[3]\n",
    "\n",
    "    # Download the file content\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    file_stream = BytesIO()\n",
    "    downloader = MediaIoBaseDownload(file_stream, request)\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "    file_stream.seek(0)\n",
    "    content = file_stream.read().decode('utf-8')\n",
    "\n",
    "    # Add the cyclone id and name as a new column using Polars\n",
    "\n",
    "    df = pl.read_csv(BytesIO(content.encode('utf-8')),separator='\\t', has_header=False)\n",
    "    df = df.with_columns([\n",
    "    pl.lit(cyclone_id).alias(\"cyclone_id\"),\n",
    "    pl.lit(cyclone_name).alias(\"cyclone_name\")\n",
    "    ])\n",
    "\n",
    "    # Save the modified DataFrame locally\n",
    "    output_file_path = os.path.join(output_dir, file_name)\n",
    "    df.write_csv(output_file_path, separator='\\t',include_header=False)\n",
    "\n",
    "    print(f\"Processed and saved: {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 992 files for pattern 'Reduced_Trackfile'...\n",
      "Combined file saved: combined_files/Combined_Reduced_Trackfile.txt\n",
      "Combining 994 files for pattern 'WWLLN_Locations'...\n",
      "Combined file saved: combined_files/Combined_WWLLN_Locations.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Directories for processed files and output\n",
    "input_dir = \"processed_files\"\n",
    "output_dir = \"combined_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# File patterns to combine\n",
    "patterns = {\n",
    "    \"Reduced_Trackfile\": os.path.join(input_dir, \"*Reduced_Trackfile*.txt\"),\n",
    "    \"WWLLN_Locations\": os.path.join(input_dir, \"*WWLLN_Locations*.txt\")\n",
    "}\n",
    "\n",
    "# Combine files based on patterns\n",
    "for pattern_name, pattern_path in patterns.items():\n",
    "    combined_content = []\n",
    "    output_file_path = os.path.join(output_dir, f\"Combined_{pattern_name}.txt\")\n",
    "\n",
    "    # Find all matching files\n",
    "    matching_files = glob.glob(pattern_path)\n",
    "    print(f\"Combining {len(matching_files)} files for pattern '{pattern_name}'...\")\n",
    "\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        for file_path in matching_files:\n",
    "            with open(file_path, \"r\") as input_file:\n",
    "                for line in input_file:\n",
    "                    output_file.write(line)\n",
    "\n",
    "    print(f\"Combined file saved: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
