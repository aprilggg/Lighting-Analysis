{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Files - Creating and Cleaning Consolidated Data Files\n",
    "\n",
    "This notebook adds two necessary columns to our data files and combines the individual `.txt` files into two larger `.txt` files. Execution of this notebook will create `Combined_Reduced_Trackfile.txt` and `Combined_WWLLN_Locations.txt`. This notebook should be executed after the `data_file_cleaning.ipynb` notebook.\n",
    "\n",
    "We then perform some post-processing on the data by adding column headers, filtering to tropical cyclones that are category 1 or higher, and calculating the direct distance of each lightning strike to the TC storm center. This will create additional `Filtered_Reduced_Trackfile.csv` and `Filtered_WWLLN_Locations.txt` files for use in analysis. \n",
    "\n",
    "The last part of this notebook joins the trackfile and WWLLN locations together, where we bin the lightning data by 30 minute increments and join to the closest storm center timestamp to get the wind speed and pressure data. This portion will create the `some file` for use in analysis.\n",
    "\n",
    "### Combining Files\n",
    "We use the [Google Drive API](https://developers.google.com/drive/api/guides/about-sdk) to download the files previously uploaded in `data_upload.ipynb` to consolidate the individual files. The first half of the code works if the Google Drive API is already set up (refer to instructions in `data_upload.ipynb`). The code after we create the list of files is not dependent on the Google Drive API.\n",
    "\n",
    "Let's start by installing necessary packages and then importing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "import os\n",
    "import polars as pl\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from io import BytesIO\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the function in `data_file_cleaning.ipynb`, we use the following function to authenticate the Google Drive API. This will open a browser to perform the authentication process. \n",
    "\n",
    "Check if a `token.pickle` file already exists before running the following code. If the file exists, it is recommended to delete it before running the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=389849867563-4uggnm57nqe52156v32gj1lkosoqpoem.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A37635%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=GyfvJGpr2mtpuRzI6AP8xi3h1k3QIH&access_type=offline\n"
     ]
    }
   ],
   "source": [
    "# Scopes for accessing Google Drive\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "# Authenticate and create the service object\n",
    "def authenticate_drive_api():\n",
    "    creds = None\n",
    "    # Token file for saving the authentication\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "    # If there are no credentials, perform authentication\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'client_secrets.json', SCOPES)  # Ensure 'credentials.json' is downloaded from Google API Console\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for future use\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# Initialize the service object\n",
    "service = authenticate_drive_api()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next function grabs the list of all files in a specified folder that are not trashed and stores them into a list. Each file has an ID and name attribute that we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(folder_id):\n",
    "    # Query to find files in the specified folder\n",
    "    query = f\"'{folder_id}' in parents and trashed=false\"\n",
    "    files = []\n",
    "\n",
    "    # List files in the folder and append to list\n",
    "    page_token = None\n",
    "    while True:\n",
    "        response = service.files().list(\n",
    "            q=query,\n",
    "            spaces='drive',\n",
    "            fields='nextPageToken, files(id, name)',\n",
    "            pageToken=page_token\n",
    "        ).execute()\n",
    "\n",
    "        files += response.get('files', [])\n",
    "\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "        if page_token is None:\n",
    "            break\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the function to find files in the specified folder. The folder ID can be found as the string after the \"folders/\" part of the URL for the Google Drive folder. This will give us a list of files to iterate through for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the folder\n",
    "folder_id = '14idmMBbM5xXZg4b61iINHbBTl2z4yLeD'\n",
    "files = find_files(folder_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split out the tropical cyclone ID and name from each of the files to add as a separate column. We then save the files in the `processed_files` directory for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file to add cyclone ID and name as columns\n",
    "# Directory to save the processed files locally\n",
    "output_dir = \"processed_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    file_id = file['id']\n",
    "    file_name = file['name']\n",
    "\n",
    "    # Extract the cyclone ID and name from the filename\n",
    "    cyclone_id = '_'.join(file_name.split('_')[:3])\n",
    "    cyclone_name = file_name.split('_')[3]\n",
    "\n",
    "    # Download the file content\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    file_stream = BytesIO()\n",
    "    downloader = MediaIoBaseDownload(file_stream, request)\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "    file_stream.seek(0)\n",
    "    content = file_stream.read().decode('utf-8')\n",
    "\n",
    "    # Add the cyclone id and name as a new column using Polars\n",
    "    df = pl.read_csv(BytesIO(content.encode('utf-8')),separator='\\t', has_header=False)\n",
    "    df = df.with_columns([\n",
    "    pl.lit(cyclone_id).alias(\"cyclone_id\"),\n",
    "    pl.lit(cyclone_name).alias(\"cyclone_name\")\n",
    "    ])\n",
    "\n",
    "    # Save the modified DataFrame locally\n",
    "    output_file_path = os.path.join(output_dir, file_name)\n",
    "    df.write_csv(output_file_path, separator='\\t',include_header=False)\n",
    "\n",
    "    print(f\"Processed and saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine each of the trackfiles in the `processed_files` folder into one file, and each of the WWLLN location files into one file. This will give us two output files in the `combined_files` folder - `Combined_Reduced_Trackfile.txt` and `Combined_WWLLN_Locations.txt`. We will use these files as the basis for our subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 992 files for pattern 'Reduced_Trackfile'...\n",
      "Combined file saved: combined_files/Combined_Reduced_Trackfile.txt\n",
      "Combining 994 files for pattern 'WWLLN_Locations'...\n",
      "Combined file saved: combined_files/Combined_WWLLN_Locations.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Directories for processed files and output\n",
    "input_dir = \"processed_files\"\n",
    "output_dir = \"combined_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# File patterns to combine\n",
    "patterns = {\n",
    "    \"Reduced_Trackfile\": os.path.join(input_dir, \"*Reduced_Trackfile*.txt\"),\n",
    "    \"WWLLN_Locations\": os.path.join(input_dir, \"*WWLLN_Locations*.txt\")\n",
    "}\n",
    "\n",
    "# Combine files based on patterns\n",
    "for pattern_name, pattern_path in patterns.items():\n",
    "    combined_content = []\n",
    "    output_file_path = os.path.join(output_dir, f\"Combined_{pattern_name}.txt\")\n",
    "\n",
    "    # Find all matching files\n",
    "    matching_files = glob.glob(pattern_path)\n",
    "    print(f\"Combining {len(matching_files)} files for pattern '{pattern_name}'...\")\n",
    "\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        for file_path in matching_files:\n",
    "            with open(file_path, \"r\") as input_file:\n",
    "                for line in input_file:\n",
    "                    output_file.write(line)\n",
    "\n",
    "    print(f\"Combined file saved: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Processing\n",
    "In this section we add a column header to the files and filter down to TCs that are category 1 and above. Category 1 is defined using the [Saffir-Simpson Hurricane Wind Scale](https://www.nhc.noaa.gov/aboutsshws.php), where the maximum sustained wind speed is between 64-82 kt. We calculate each TC's category using the Saffir-Simpson Scale and save it in a new column. We then calculate the direct distance of each lightning strike to the storm center and denote it as inner core or rainband. This section outputs `Filtered_Reduced_Trackfile.csv` and `Filtered_WWLLN_Locations.txt` files.\n",
    "\n",
    "Start by importing the necessary libraries and files created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import txt files created earlier\n",
    "# define the path to file below\n",
    "# trackfile_path = \"Combined_Reduced_Trackfile.txt\"\n",
    "# wwlln_path = \"Combined_WWLLN_Locations.txt\"\n",
    "\n",
    "# track_file = pd.read_csv(trackfile_path, sep=\"\\t\")\n",
    "# track_file = track_file.drop(track_file.columns[8], axis=1) # drop the column of zeros\n",
    "\n",
    "\n",
    "#!!!! commented out bc elaine's computer will die so this is for u janice <3\n",
    "chunksize = 100000  # Process 100,000 rows at a time\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    r\"C:\\Users\\user\\Desktop\\25 WI\\Combined_WWLLN_Locations.txt\",\n",
    "    delim_whitespace=True,\n",
    "    chunksize=chunksize\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "locations_WWLLN = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_track_file = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\Filtered_Reduced_Trackfile.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add headers to the two dataframes for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_file.columns = ['year', 'month', 'day','hour','lat','lon','pressure', 'knots', 'storm_code', 'storm_name']\n",
    "#locations_WWLLN.columns = ['year', 'month', 'day', 'hour', 'min', 'sec','lat','lon','distance_from_storm_center_km_east', 'distance_from_storm_center_km_north', 'storm_code','storm_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we process the trackfile data by creating the list of storm codes that meet the category 1 or higher requirement. We will use this list to filter the wind speed/pressure data as well as the lightning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm_code</th>\n",
       "      <th>max_wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_10_1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL_10_10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_10_11</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_10_12</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_10_13</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  storm_code  max_wind_speed\n",
       "0   ATL_10_1              85\n",
       "1  ATL_10_10              30\n",
       "2  ATL_10_11             135\n",
       "3  ATL_10_12             120\n",
       "4  ATL_10_13             105"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the max wind speed for each storm code\n",
    "max_wind_speed = track_file.groupby('storm_code').agg(\n",
    "    max_wind_speed=('knots', 'max')\n",
    ").reset_index()\n",
    "max_wind_speed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm_code</th>\n",
       "      <th>category</th>\n",
       "      <th>basin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_10_1</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_10_11</td>\n",
       "      <td>4</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_10_12</td>\n",
       "      <td>4</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_10_13</td>\n",
       "      <td>3</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ATL_10_14</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  storm_code  category basin\n",
       "0   ATL_10_1         2   ATL\n",
       "2  ATL_10_11         4   ATL\n",
       "3  ATL_10_12         4   ATL\n",
       "4  ATL_10_13         3   ATL\n",
       "5  ATL_10_14         1   ATL"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by max >= 64 knots\n",
    "storm_filter = max_wind_speed[max_wind_speed[\"max_wind_speed\"] >= 64].copy()\n",
    "\n",
    "# calculate the TC category using the max wind speed\n",
    "storm_filter[\"category\"] = storm_filter[\"max_wind_speed\"].apply(\n",
    "    lambda x: 1 if 64 <= x <= 82 else (2 if 82 < x <= 95 else (3 if 95 < x <= 112 else (4 if 112 < x <= 136 else (5 if x > 136 else 0))))\n",
    ")\n",
    "storm_filter = storm_filter[[\"storm_code\", \"category\"]]\n",
    "\n",
    "# strip the basin from the storm code\n",
    "storm_filter[\"basin\"] = storm_filter[\"storm_code\"].str.extract(r\"^(.*?)_\")\n",
    "\n",
    "storm_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall number of TCs: 982, category 1 or higher number of TCs: 473\n"
     ]
    }
   ],
   "source": [
    "print(f\"Overall number of TCs: {len(max_wind_speed)}, category 1 or higher number of TCs: {len(storm_filter)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pressure</th>\n",
       "      <th>knots</th>\n",
       "      <th>storm_code</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>category</th>\n",
       "      <th>basin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-80.1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-80.2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13.2</td>\n",
       "      <td>-80.3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-80.4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour   lat   lon  pressure  knots storm_code storm_name  \\\n",
       "0  2020     10   20     0  12.1 -80.0         0     15  ATL_20_28       Zeta   \n",
       "1  2020     10   20     6  12.5 -80.1         0     15  ATL_20_28       Zeta   \n",
       "2  2020     10   20    12  12.8 -80.2         0     15  ATL_20_28       Zeta   \n",
       "3  2020     10   20    18  13.2 -80.3         0     15  ATL_20_28       Zeta   \n",
       "4  2020     10   21     0  13.8 -80.4         0     15  ATL_20_28       Zeta   \n",
       "\n",
       "   category basin  \n",
       "0         2   ATL  \n",
       "1         2   ATL  \n",
       "2         2   ATL  \n",
       "3         2   ATL  \n",
       "4         2   ATL  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter the trackfile data by the storm filter\n",
    "track_file_filtered = track_file[track_file[\"storm_code\"].isin(storm_filter[\"storm_code\"])]\n",
    "# join the category column by storm code\n",
    "track_file_filtered = pd.merge(track_file_filtered, storm_filter, how='inner', on='storm_code')\n",
    "\n",
    "track_file_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this as a csv file for use in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_file_filtered.to_csv('Filtered_Reduced_Trackfile.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's focus on the WWLLN dataset. Start by filtering the WWLLN dataset by the storm filter created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pressure</th>\n",
       "      <th>knots</th>\n",
       "      <th>storm_code</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>category</th>\n",
       "      <th>basin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>-80.1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>12.8</td>\n",
       "      <td>-80.2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13.2</td>\n",
       "      <td>-80.3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-80.4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>ATL_20_28</td>\n",
       "      <td>Zeta</td>\n",
       "      <td>2</td>\n",
       "      <td>ATL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour   lat   lon  pressure  knots storm_code storm_name  \\\n",
       "0  2020     10   20     0  12.1 -80.0         0     15  ATL_20_28       Zeta   \n",
       "1  2020     10   20     6  12.5 -80.1         0     15  ATL_20_28       Zeta   \n",
       "2  2020     10   20    12  12.8 -80.2         0     15  ATL_20_28       Zeta   \n",
       "3  2020     10   20    18  13.2 -80.3         0     15  ATL_20_28       Zeta   \n",
       "4  2020     10   21     0  13.8 -80.4         0     15  ATL_20_28       Zeta   \n",
       "\n",
       "   category basin  \n",
       "0         2   ATL  \n",
       "1         2   ATL  \n",
       "2         2   ATL  \n",
       "3         2   ATL  \n",
       "4         2   ATL  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_track_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Janice from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN.columns = ['year', 'month', 'day', 'hour', 'min', 'sec','lat','lon','distance_from_storm_center_km_east', 'distance_from_storm_center_km_north', 'storm_code','storm_name']  # Replace with actual names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>distance_from_storm_center_km_east</th>\n",
       "      <th>distance_from_storm_center_km_north</th>\n",
       "      <th>storm_code</th>\n",
       "      <th>storm_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735356</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>13.4587</td>\n",
       "      <td>-96.2292</td>\n",
       "      <td>234.752</td>\n",
       "      <td>228.917</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735357</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0418</td>\n",
       "      <td>13.3158</td>\n",
       "      <td>-96.3223</td>\n",
       "      <td>224.818</td>\n",
       "      <td>213.027</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735358</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>9.4671</td>\n",
       "      <td>12.9812</td>\n",
       "      <td>-88.4452</td>\n",
       "      <td>1078.570</td>\n",
       "      <td>175.821</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735359</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>9.4150</td>\n",
       "      <td>13.0012</td>\n",
       "      <td>-88.4697</td>\n",
       "      <td>1075.820</td>\n",
       "      <td>178.045</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735360</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>9.4671</td>\n",
       "      <td>12.9800</td>\n",
       "      <td>-88.4276</td>\n",
       "      <td>1080.480</td>\n",
       "      <td>175.688</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  month  day  hour  min     sec      lat      lon  \\\n",
       "735356  2016     10   22     5   56  0.6103  13.4587 -96.2292   \n",
       "735357  2016     10   22     5   56  1.0418  13.3158 -96.3223   \n",
       "735358  2016     10   22     5   56  9.4671  12.9812 -88.4452   \n",
       "735359  2016     10   22     5   56  9.4150  13.0012 -88.4697   \n",
       "735360  2016     10   22     5   56  9.4671  12.9800 -88.4276   \n",
       "\n",
       "        distance_from_storm_center_km_east  \\\n",
       "735356                             234.752   \n",
       "735357                             224.818   \n",
       "735358                            1078.570   \n",
       "735359                            1075.820   \n",
       "735360                            1080.480   \n",
       "\n",
       "        distance_from_storm_center_km_north  storm_code storm_name  \n",
       "735356                              228.917  EPAC_16_20    Seymour  \n",
       "735357                              213.027  EPAC_16_20    Seymour  \n",
       "735358                              175.821  EPAC_16_20    Seymour  \n",
       "735359                              178.045  EPAC_16_20    Seymour  \n",
       "735360                              175.688  EPAC_16_20    Seymour  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter WWLLN dataset by the storm filter\n",
    "locations_WWLLN_filtered = locations_WWLLN[locations_WWLLN[\"storm_code\"].isin(filtered_track_file[\"storm_code\"])]\n",
    "locations_WWLLN_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the direct distance of each lightning instance from the storm center using a simple triangle calculation. We have the north and east distances from center, so we use the Pythagorean theorem to simply calculate the missing hypotenuse. We also create an indicator for inner core lightning and another for rainband lightning. Inner core is defined as within 100km of storm center, while rainband is defined as between 200-400km of storm center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143111669, 12)\n"
     ]
    }
   ],
   "source": [
    "print(locations_WWLLN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77535990, 12)\n"
     ]
    }
   ],
   "source": [
    "print(locations_WWLLN_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26800\\3001479597.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations_WWLLN_filtered['hypotenuse_disance_from_storm_center'] = np.sqrt(locations_WWLLN_filtered['distance_from_storm_center_km_east'] ** 2 +locations_WWLLN['distance_from_storm_center_km_north'] ** 2)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26800\\3001479597.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations_WWLLN_filtered[\"inner_core_ind\"] = locations_WWLLN_filtered[\"hypotenuse_disance_from_storm_center\"].apply(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_26800\\3001479597.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations_WWLLN_filtered[\"rainband_ind\"] = locations_WWLLN_filtered[\"hypotenuse_disance_from_storm_center\"].apply(\n"
     ]
    }
   ],
   "source": [
    "locations_WWLLN_filtered['hypotenuse_disance_from_storm_center'] = np.sqrt(locations_WWLLN_filtered['distance_from_storm_center_km_east'] ** 2 +locations_WWLLN['distance_from_storm_center_km_north'] ** 2)\n",
    "locations_WWLLN_filtered[\"inner_core_ind\"] = locations_WWLLN_filtered[\"hypotenuse_disance_from_storm_center\"].apply(\n",
    "    lambda x: 1 if x <= 100 else 0\n",
    ")\n",
    "locations_WWLLN_filtered[\"rainband_ind\"] = locations_WWLLN_filtered[\"hypotenuse_disance_from_storm_center\"].apply(\n",
    "     lambda x: 1 if (x >= 200 and x <= 400) else 0 # pls check if this works i didnt run it and then delete this comment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15952\\933412928.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations_WWLLN_filtered[\"rainband_ind\"] = locations_WWLLN_filtered[\"hypotenuse_disance_from_storm_center\"].apply(\n"
     ]
    }
   ],
   "source": [
    "locations_WWLLN_filtered[\"rainband_ind\"] = locations_WWLLN_filtered[\"hypotenuse_disance_from_storm_center\"].apply(\n",
    "     lambda x: 1 if (x >= 200 and x <= 400) else 0 # pls check if this works i didnt run it and then delete this comment\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered.to_csv(\"Filtered_WWLLN_Locations.txt\", sep=' ', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 100000  # Process 100,000 rows at a time\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    r\"C:\\Users\\user\\Desktop\\25 WI\\Filtered_WWLLN_Locations.txt\",\n",
    "    delim_whitespace=True,\n",
    "    chunksize=chunksize\n",
    "):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "locations_WWLLN_filtered_ = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>distance_from_storm_center_km_east</th>\n",
       "      <th>distance_from_storm_center_km_north</th>\n",
       "      <th>storm_code</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>hypotenuse_disance_from_storm_center</th>\n",
       "      <th>inner_core_ind</th>\n",
       "      <th>rainband_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>13.4587</td>\n",
       "      <td>-96.2292</td>\n",
       "      <td>234.752</td>\n",
       "      <td>228.917</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>327.889455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0418</td>\n",
       "      <td>13.3158</td>\n",
       "      <td>-96.3223</td>\n",
       "      <td>224.818</td>\n",
       "      <td>213.027</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>309.715411</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>9.4671</td>\n",
       "      <td>12.9812</td>\n",
       "      <td>-88.4452</td>\n",
       "      <td>1078.570</td>\n",
       "      <td>175.821</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>1092.806602</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>9.4150</td>\n",
       "      <td>13.0012</td>\n",
       "      <td>-88.4697</td>\n",
       "      <td>1075.820</td>\n",
       "      <td>178.045</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>1090.453435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>9.4671</td>\n",
       "      <td>12.9800</td>\n",
       "      <td>-88.4276</td>\n",
       "      <td>1080.480</td>\n",
       "      <td>175.688</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>1094.670409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  min     sec      lat      lon  \\\n",
       "0  2016     10   22     5   56  0.6103  13.4587 -96.2292   \n",
       "1  2016     10   22     5   56  1.0418  13.3158 -96.3223   \n",
       "2  2016     10   22     5   56  9.4671  12.9812 -88.4452   \n",
       "3  2016     10   22     5   56  9.4150  13.0012 -88.4697   \n",
       "4  2016     10   22     5   56  9.4671  12.9800 -88.4276   \n",
       "\n",
       "   distance_from_storm_center_km_east  distance_from_storm_center_km_north  \\\n",
       "0                             234.752                              228.917   \n",
       "1                             224.818                              213.027   \n",
       "2                            1078.570                              175.821   \n",
       "3                            1075.820                              178.045   \n",
       "4                            1080.480                              175.688   \n",
       "\n",
       "   storm_code storm_name  hypotenuse_disance_from_storm_center  \\\n",
       "0  EPAC_16_20    Seymour                            327.889455   \n",
       "1  EPAC_16_20    Seymour                            309.715411   \n",
       "2  EPAC_16_20    Seymour                           1092.806602   \n",
       "3  EPAC_16_20    Seymour                           1090.453435   \n",
       "4  EPAC_16_20    Seymour                           1094.670409   \n",
       "\n",
       "   inner_core_ind  rainband_ind  \n",
       "0               0             1  \n",
       "1               0             1  \n",
       "2               0             0  \n",
       "3               0             0  \n",
       "4               0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_WWLLN_filtered_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_inner_rainband = locations_WWLLN_filtered_[\n",
    "    ~((locations_WWLLN_filtered_[\"rainband_ind\"] == 0) & (locations_WWLLN_filtered_[\"inner_core_ind\"] == 0))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2611951, 15)\n"
     ]
    }
   ],
   "source": [
    "locations_WWLLN_filtered_innercore = locations_WWLLN_filtered_inner_rainband[locations_WWLLN_filtered_inner_rainband['inner_core_ind'] == 1]\n",
    "print(locations_WWLLN_filtered_innercore.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10146702, 15)\n"
     ]
    }
   ],
   "source": [
    "locations_WWLLN_filtered_rainband = locations_WWLLN_filtered_inner_rainband[locations_WWLLN_filtered_inner_rainband['rainband_ind'] == 1]\n",
    "print(locations_WWLLN_filtered_rainband.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_innercore.to_csv(\"WWLLN_innercore.csv\", index=False)\n",
    "locations_WWLLN_filtered_rainband.to_csv(\"WWLLN_rainband.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_innercore = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\WWLLN_innercore_original.csv\")\n",
    "locations_WWLLN_filtered_rainband = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\WWLLN_rainband_original.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this as a txt file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>distance_from_storm_center_km_east</th>\n",
       "      <th>distance_from_storm_center_km_north</th>\n",
       "      <th>storm_code</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>hypotenuse_disance_from_storm_center</th>\n",
       "      <th>inner_core_ind</th>\n",
       "      <th>rainband_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>10.5194</td>\n",
       "      <td>12.2078</td>\n",
       "      <td>-99.0228</td>\n",
       "      <td>-51.2569</td>\n",
       "      <td>85.3196</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>99.532427</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>58.6195</td>\n",
       "      <td>11.2449</td>\n",
       "      <td>-98.8947</td>\n",
       "      <td>-17.5788</td>\n",
       "      <td>-27.2301</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>32.411303</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>58.6161</td>\n",
       "      <td>11.1921</td>\n",
       "      <td>-98.8502</td>\n",
       "      <td>-12.7280</td>\n",
       "      <td>-33.1012</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>35.463945</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>41.9061</td>\n",
       "      <td>12.1096</td>\n",
       "      <td>-99.3377</td>\n",
       "      <td>-65.6873</td>\n",
       "      <td>68.9202</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>95.209324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>47.8987</td>\n",
       "      <td>11.5981</td>\n",
       "      <td>-99.5928</td>\n",
       "      <td>-86.9552</td>\n",
       "      <td>10.2015</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>87.551570</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  min      sec      lat      lon  \\\n",
       "0  2016     10   22     6   53  10.5194  12.2078 -99.0228   \n",
       "1  2016     10   22     7   53  58.6195  11.2449 -98.8947   \n",
       "2  2016     10   22     7   53  58.6161  11.1921 -98.8502   \n",
       "3  2016     10   22     7   54  41.9061  12.1096 -99.3377   \n",
       "4  2016     10   22     8   13  47.8987  11.5981 -99.5928   \n",
       "\n",
       "   distance_from_storm_center_km_east  distance_from_storm_center_km_north  \\\n",
       "0                            -51.2569                              85.3196   \n",
       "1                            -17.5788                             -27.2301   \n",
       "2                            -12.7280                             -33.1012   \n",
       "3                            -65.6873                              68.9202   \n",
       "4                            -86.9552                              10.2015   \n",
       "\n",
       "   storm_code storm_name  hypotenuse_disance_from_storm_center  \\\n",
       "0  EPAC_16_20    Seymour                             99.532427   \n",
       "1  EPAC_16_20    Seymour                             32.411303   \n",
       "2  EPAC_16_20    Seymour                             35.463945   \n",
       "3  EPAC_16_20    Seymour                             95.209324   \n",
       "4  EPAC_16_20    Seymour                             87.551570   \n",
       "\n",
       "   inner_core_ind  rainband_ind  \n",
       "0               1             0  \n",
       "1               1             0  \n",
       "2               1             0  \n",
       "3               1             0  \n",
       "4               1             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_WWLLN_filtered_innercore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_21336\\2364616314.py:19: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  locations_WWLLN_filtered_innercore = locations_WWLLN_filtered_innercore.groupby('storm_code').apply(add_time_bin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  hour  min      sec      lat      lon  \\\n",
      "0  2016     10   22     6   53  10.5194  12.2078 -99.0228   \n",
      "1  2016     10   22     7   53  58.6195  11.2449 -98.8947   \n",
      "2  2016     10   22     7   53  58.6161  11.1921 -98.8502   \n",
      "3  2016     10   22     7   54  41.9061  12.1096 -99.3377   \n",
      "4  2016     10   22     8   13  47.8987  11.5981 -99.5928   \n",
      "\n",
      "   distance_from_storm_center_km_east  distance_from_storm_center_km_north  \\\n",
      "0                            -51.2569                              85.3196   \n",
      "1                            -17.5788                             -27.2301   \n",
      "2                            -12.7280                             -33.1012   \n",
      "3                            -65.6873                              68.9202   \n",
      "4                            -86.9552                              10.2015   \n",
      "\n",
      "   storm_code storm_name  hypotenuse_disance_from_storm_center  \\\n",
      "0  EPAC_16_20    Seymour                             99.532427   \n",
      "1  EPAC_16_20    Seymour                             32.411303   \n",
      "2  EPAC_16_20    Seymour                             35.463945   \n",
      "3  EPAC_16_20    Seymour                             95.209324   \n",
      "4  EPAC_16_20    Seymour                             87.551570   \n",
      "\n",
      "   inner_core_ind  rainband_ind                   datetime            time_bin  \n",
      "0               1             0 2016-10-22 06:53:10.519400 2016-10-22 06:30:00  \n",
      "1               1             0 2016-10-22 07:53:58.619500 2016-10-22 07:30:00  \n",
      "2               1             0 2016-10-22 07:53:58.616100 2016-10-22 07:30:00  \n",
      "3               1             0 2016-10-22 07:54:41.906100 2016-10-22 07:30:00  \n",
      "4               1             0 2016-10-22 08:13:47.898700 2016-10-22 08:00:00  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming your columns are 'year', 'month', 'day', 'hour', 'minute', 'second', and 'storm_code'\n",
    "# Create a datetime column from the existing columns\n",
    "#locations_WWLLN_filtered_innercore['datetime'] = pd.to_datetime(locations_WWLLN_filtered_innercore[['year', 'month', 'day', 'hour', 'min', 'sec']])\n",
    "locations_WWLLN_filtered_innercore['sec'] = locations_WWLLN_filtered_innercore['sec'].apply(lambda x: 0 if x == 60 else x)\n",
    "\n",
    "locations_WWLLN_filtered_innercore['datetime'] = pd.to_datetime(locations_WWLLN_filtered_innercore['year'].astype(str) + '-' +\n",
    "                                 locations_WWLLN_filtered_innercore['month'].astype(str).str.zfill(2) + '-' +\n",
    "                                 locations_WWLLN_filtered_innercore['day'].astype(str).str.zfill(2) + ' ' +\n",
    "                                 locations_WWLLN_filtered_innercore['hour'].astype(str).str.zfill(2) + ':' +\n",
    "                                 locations_WWLLN_filtered_innercore['min'].astype(str).str.zfill(2) + ':' +\n",
    "                                 locations_WWLLN_filtered_innercore['sec'].astype(str).str.zfill(2))\n",
    "\n",
    "# Define a function to apply the 30-minute binning for each storm_code group\n",
    "def add_time_bin(group):\n",
    "    group['time_bin'] = group['datetime'].dt.floor('30T')\n",
    "    return group\n",
    "\n",
    "# Group by storm_code and apply the binning function\n",
    "locations_WWLLN_filtered_innercore = locations_WWLLN_filtered_innercore.groupby('storm_code').apply(add_time_bin)\n",
    "\n",
    "# Print the resulting DataFrame with the new 'time_bin' column\n",
    "print(locations_WWLLN_filtered_innercore.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27748\\3369465188.py:16: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  locations_WWLLN_filtered_rainband = locations_WWLLN_filtered_rainband.groupby('storm_code').apply(add_time_bin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>min</th>\n",
       "      <th>sec</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>distance_from_storm_center_km_east</th>\n",
       "      <th>distance_from_storm_center_km_north</th>\n",
       "      <th>storm_code</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>hypotenuse_disance_from_storm_center</th>\n",
       "      <th>inner_core_ind</th>\n",
       "      <th>rainband_ind</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>13.4587</td>\n",
       "      <td>-96.2292</td>\n",
       "      <td>234.752</td>\n",
       "      <td>228.917</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>327.889455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-22 05:56:00.610300</td>\n",
       "      <td>2016-10-22 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0418</td>\n",
       "      <td>13.3158</td>\n",
       "      <td>-96.3223</td>\n",
       "      <td>224.818</td>\n",
       "      <td>213.027</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>309.715411</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-22 05:56:01.041800</td>\n",
       "      <td>2016-10-22 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>54.1845</td>\n",
       "      <td>13.2070</td>\n",
       "      <td>-96.1878</td>\n",
       "      <td>239.479</td>\n",
       "      <td>200.929</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>312.606229</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-22 05:56:54.184500</td>\n",
       "      <td>2016-10-22 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>54.2637</td>\n",
       "      <td>13.3043</td>\n",
       "      <td>-96.2315</td>\n",
       "      <td>234.654</td>\n",
       "      <td>211.748</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>316.069162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-22 05:56:54.263700</td>\n",
       "      <td>2016-10-22 05:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>54.3229</td>\n",
       "      <td>13.2674</td>\n",
       "      <td>-96.2462</td>\n",
       "      <td>233.099</td>\n",
       "      <td>207.645</td>\n",
       "      <td>EPAC_16_20</td>\n",
       "      <td>Seymour</td>\n",
       "      <td>312.172372</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-22 05:56:54.322900</td>\n",
       "      <td>2016-10-22 05:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  min      sec      lat      lon  \\\n",
       "0  2016     10   22     5   56   0.6103  13.4587 -96.2292   \n",
       "1  2016     10   22     5   56   1.0418  13.3158 -96.3223   \n",
       "2  2016     10   22     5   56  54.1845  13.2070 -96.1878   \n",
       "3  2016     10   22     5   56  54.2637  13.3043 -96.2315   \n",
       "4  2016     10   22     5   56  54.3229  13.2674 -96.2462   \n",
       "\n",
       "   distance_from_storm_center_km_east  distance_from_storm_center_km_north  \\\n",
       "0                             234.752                              228.917   \n",
       "1                             224.818                              213.027   \n",
       "2                             239.479                              200.929   \n",
       "3                             234.654                              211.748   \n",
       "4                             233.099                              207.645   \n",
       "\n",
       "   storm_code storm_name  hypotenuse_disance_from_storm_center  \\\n",
       "0  EPAC_16_20    Seymour                            327.889455   \n",
       "1  EPAC_16_20    Seymour                            309.715411   \n",
       "2  EPAC_16_20    Seymour                            312.606229   \n",
       "3  EPAC_16_20    Seymour                            316.069162   \n",
       "4  EPAC_16_20    Seymour                            312.172372   \n",
       "\n",
       "   inner_core_ind  rainband_ind                   datetime            time_bin  \n",
       "0               0             1 2016-10-22 05:56:00.610300 2016-10-22 05:30:00  \n",
       "1               0             1 2016-10-22 05:56:01.041800 2016-10-22 05:30:00  \n",
       "2               0             1 2016-10-22 05:56:54.184500 2016-10-22 05:30:00  \n",
       "3               0             1 2016-10-22 05:56:54.263700 2016-10-22 05:30:00  \n",
       "4               0             1 2016-10-22 05:56:54.322900 2016-10-22 05:30:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_WWLLN_filtered_rainband['sec'] = locations_WWLLN_filtered_rainband['sec'].apply(lambda x: 0 if x == 60 else x)\n",
    "\n",
    "locations_WWLLN_filtered_rainband['datetime'] = pd.to_datetime(locations_WWLLN_filtered_rainband['year'].astype(str) + '-' +\n",
    "                                 locations_WWLLN_filtered_rainband['month'].astype(str).str.zfill(2) + '-' +\n",
    "                                 locations_WWLLN_filtered_rainband['day'].astype(str).str.zfill(2) + ' ' +\n",
    "                                 locations_WWLLN_filtered_rainband['hour'].astype(str).str.zfill(2) + ':' +\n",
    "                                 locations_WWLLN_filtered_rainband['min'].astype(str).str.zfill(2) + ':' +\n",
    "                                 locations_WWLLN_filtered_rainband['sec'].astype(str).str.zfill(2))\n",
    "\n",
    "# Define a function to apply the 30-minute binning for each storm_code group\n",
    "def add_time_bin(group):\n",
    "    group['time_bin'] = group['datetime'].dt.floor('30T')\n",
    "    return group\n",
    "\n",
    "# Group by storm_code and apply the binning function\n",
    "locations_WWLLN_filtered_rainband = locations_WWLLN_filtered_rainband.groupby('storm_code').apply(add_time_bin)\n",
    "\n",
    "# Print the resulting DataFrame with the new 'time_bin' column\n",
    "locations_WWLLN_filtered_rainband.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_innercore_grouped = locations_WWLLN_filtered_innercore.groupby(['storm_code', 'time_bin'])\n",
    "locations_WWLLN_filtered_innercore_timebin = locations_WWLLN_filtered_innercore_grouped.size().reset_index(name='lightining_count')\n",
    "\n",
    "locations_WWLLN_filtered_innercore_timebin = locations_WWLLN_filtered_innercore_timebin.sort_values(by = ['storm_code', 'time_bin'])\n",
    "\n",
    "\n",
    "locations_WWLLN_filtered_innercore.to_csv(\"WWLLN_innercore_w_time.csv\", index=False)\n",
    "locations_WWLLN_filtered_innercore_timebin.to_csv(\"WWLLN_innercore_timebin_count.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_rainband_grouped = locations_WWLLN_filtered_rainband.groupby(['storm_code', 'time_bin'])\n",
    "locations_WWLLN_filtered_rainband_timebin = locations_WWLLN_filtered_rainband_grouped.size().reset_index(name='lightining_count')\n",
    "\n",
    "locations_WWLLN_filtered_rainband_timebin = locations_WWLLN_filtered_rainband_timebin.sort_values(by = ['storm_code', 'time_bin'])\n",
    "\n",
    "locations_WWLLN_filtered_rainband_timebin.to_csv(\"WWLLN_rainband_timebin_count.csv\", index=False)\n",
    "locations_WWLLN_filtered_rainband.to_csv(\"WWLLN_rainband_w_time.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_reduced_trackfile = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\Filtered_Reduced_Trackfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_rainband_timebin = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\WWLLN_rainband_timebin_count.csv\")\n",
    "locations_WWLLN_filtered_rainband = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\WWLLN_rainband_w_time.csv\")\n",
    "locations_WWLLN_filtered_innercore_timebin = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\WWLLN_innercore_timebin_count.csv\")\n",
    "locations_WWLLN_filtered_innercore = pd.read_csv(r\"C:\\Users\\user\\Desktop\\25 WI\\WWLLN_innercore_w_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_rainband_timebin[\"time_bin\"] = pd.to_datetime(locations_WWLLN_filtered_rainband_timebin[\"time_bin\"])\n",
    "\n",
    "\n",
    "locations_WWLLN_filtered_rainband_timebin[\"year\"] = locations_WWLLN_filtered_rainband_timebin[\"time_bin\"].dt.year\n",
    "locations_WWLLN_filtered_rainband_timebin[\"month\"] = locations_WWLLN_filtered_rainband_timebin[\"time_bin\"].dt.month\n",
    "locations_WWLLN_filtered_rainband_timebin[\"day\"] = locations_WWLLN_filtered_rainband_timebin[\"time_bin\"].dt.day\n",
    "locations_WWLLN_filtered_rainband_timebin[\"hour\"] = locations_WWLLN_filtered_rainband_timebin[\"time_bin\"].dt.hour\n",
    "locations_WWLLN_filtered_rainband_timebin[\"minute\"] = locations_WWLLN_filtered_rainband_timebin[\"time_bin\"].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_innercore_timebin[\"time_bin\"] = pd.to_datetime(locations_WWLLN_filtered_innercore_timebin[\"time_bin\"])\n",
    "\n",
    "\n",
    "locations_WWLLN_filtered_innercore_timebin[\"year\"] = locations_WWLLN_filtered_innercore_timebin[\"time_bin\"].dt.year\n",
    "locations_WWLLN_filtered_innercore_timebin[\"month\"] = locations_WWLLN_filtered_innercore_timebin[\"time_bin\"].dt.month\n",
    "locations_WWLLN_filtered_innercore_timebin[\"day\"] = locations_WWLLN_filtered_innercore_timebin[\"time_bin\"].dt.day\n",
    "locations_WWLLN_filtered_innercore_timebin[\"hour\"] = locations_WWLLN_filtered_innercore_timebin[\"time_bin\"].dt.hour\n",
    "locations_WWLLN_filtered_innercore_timebin[\"minute\"] = locations_WWLLN_filtered_innercore_timebin[\"time_bin\"].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_WWLLN_filtered_innercore_timebin = locations_WWLLN_filtered_innercore_timebin.sort_values(\n",
    "    [\"storm_code\", \"year\", \"month\", \"day\", \"hour\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "filtered_reduced_trackfile = filtered_reduced_trackfile.sort_values(\n",
    "    [\"storm_code\", \"year\", \"month\", \"day\", \"hour\"]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas version but requires explicit sorting which i was unsure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# innercore_joined = pd.merge_asof(\n",
    "#     locations_WWLLN_filtered_innercore_timebin.sort_values([\"storm_code\", \"year\", \"month\", \"day\", \"hour\", \"minute\"]).reset_index(drop=True),\n",
    "#     filtered_reduced_trackfile.sort_values([\"storm_code\", \"year\", \"month\", \"day\", \"hour\"]).reset_index(drop=True),\n",
    "#     on=\"hour\",\n",
    "#     by=[\"year\", \"month\", \"day\", \"storm_code\"],  # Include storm_code for grouping\n",
    "#     direction=\"backward\",  # Match closest value in the past\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainband_count_pl = pl.from_pandas(locations_WWLLN_filtered_rainband_timebin)\n",
    "rainband_w_time_pl = pl.from_pandas(locations_WWLLN_filtered_rainband)\n",
    "\n",
    "innercore_count_pl = pl.from_pandas(locations_WWLLN_filtered_innercore_timebin)\n",
    "innercore_w_time_pl = pl.from_pandas(locations_WWLLN_filtered_innercore)\n",
    "\n",
    "tracks_pl = pl.from_pandas(filtered_reduced_trackfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "innercore_joined = innercore_count_pl.join_asof(\n",
    "    tracks_pl,\n",
    "    on=\"hour\",\n",
    "    by=[\"year\", \"month\", \"day\", \"storm_code\"],  # Optional: match on multiple keys\n",
    "    strategy=\"backward\"  # \"backward\" (default) or \"forward\"\n",
    ")\n",
    "\n",
    "rainband_joined = rainband_count_pl.join_asof(\n",
    "    tracks_pl,\n",
    "    on=\"hour\",\n",
    "    by=[\"year\", \"month\", \"day\", \"storm_code\"],  # Optional: match on multiple keys\n",
    "    strategy=\"backward\"  # \"backward\" (default) or \"forward\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "innercore_joined_w_time = innercore_w_time_pl.join_asof(\n",
    "    tracks_pl,\n",
    "    on=\"hour\",\n",
    "    by=[\"year\", \"month\", \"day\", \"storm_code\"],  # Optional: match on multiple keys\n",
    "    strategy=\"backward\"  # \"backward\" (default) or \"forward\"\n",
    ")\n",
    "\n",
    "rainband_joined_w_time = rainband_w_time_pl.join_asof(\n",
    "    tracks_pl,\n",
    "    on=\"hour\",\n",
    "    by=[\"year\", \"month\", \"day\", \"storm_code\"],  # Optional: match on multiple keys\n",
    "    strategy=\"backward\"  # \"backward\" (default) or \"forward\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 24)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>year</th><th>month</th><th>day</th><th>hour</th><th>min</th><th>sec</th><th>lat</th><th>lon</th><th>distance_from_storm_center_km_east</th><th>distance_from_storm_center_km_north</th><th>storm_code</th><th>storm_name</th><th>hypotenuse_disance_from_storm_center</th><th>inner_core_ind</th><th>rainband_ind</th><th>datetime</th><th>time_bin</th><th>lat_right</th><th>lon_right</th><th>pressure</th><th>knots</th><th>storm_name_right</th><th>category</th><th>basin</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>2016</td><td>10</td><td>22</td><td>5</td><td>56</td><td>0.6103</td><td>13.4587</td><td>-96.2292</td><td>234.752</td><td>228.917</td><td>&quot;EPAC_16_20&quot;</td><td>&quot;Seymour&quot;</td><td>327.889455</td><td>0</td><td>1</td><td>&quot;2016-10-22 05:56:00.610300&quot;</td><td>&quot;2016-10-22 05:30:00&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2016</td><td>10</td><td>22</td><td>5</td><td>56</td><td>1.0418</td><td>13.3158</td><td>-96.3223</td><td>224.818</td><td>213.027</td><td>&quot;EPAC_16_20&quot;</td><td>&quot;Seymour&quot;</td><td>309.715411</td><td>0</td><td>1</td><td>&quot;2016-10-22 05:56:01.041800&quot;</td><td>&quot;2016-10-22 05:30:00&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2016</td><td>10</td><td>22</td><td>5</td><td>56</td><td>54.1845</td><td>13.207</td><td>-96.1878</td><td>239.479</td><td>200.929</td><td>&quot;EPAC_16_20&quot;</td><td>&quot;Seymour&quot;</td><td>312.606229</td><td>0</td><td>1</td><td>&quot;2016-10-22 05:56:54.184500&quot;</td><td>&quot;2016-10-22 05:30:00&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2016</td><td>10</td><td>22</td><td>5</td><td>56</td><td>54.2637</td><td>13.3043</td><td>-96.2315</td><td>234.654</td><td>211.748</td><td>&quot;EPAC_16_20&quot;</td><td>&quot;Seymour&quot;</td><td>316.069162</td><td>0</td><td>1</td><td>&quot;2016-10-22 05:56:54.263700&quot;</td><td>&quot;2016-10-22 05:30:00&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>2016</td><td>10</td><td>22</td><td>5</td><td>56</td><td>54.3229</td><td>13.2674</td><td>-96.2462</td><td>233.099</td><td>207.645</td><td>&quot;EPAC_16_20&quot;</td><td>&quot;Seymour&quot;</td><td>312.172372</td><td>0</td><td>1</td><td>&quot;2016-10-22 05:56:54.322900&quot;</td><td>&quot;2016-10-22 05:30:00&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 24)\n",
       "┌──────┬───────┬─────┬──────┬───┬───────┬──────────────────┬──────────┬───────┐\n",
       "│ year ┆ month ┆ day ┆ hour ┆ … ┆ knots ┆ storm_name_right ┆ category ┆ basin │\n",
       "│ ---  ┆ ---   ┆ --- ┆ ---  ┆   ┆ ---   ┆ ---              ┆ ---      ┆ ---   │\n",
       "│ i64  ┆ i64   ┆ i64 ┆ i64  ┆   ┆ i64   ┆ str              ┆ i64      ┆ str   │\n",
       "╞══════╪═══════╪═════╪══════╪═══╪═══════╪══════════════════╪══════════╪═══════╡\n",
       "│ 2016 ┆ 10    ┆ 22  ┆ 5    ┆ … ┆ null  ┆ null             ┆ null     ┆ null  │\n",
       "│ 2016 ┆ 10    ┆ 22  ┆ 5    ┆ … ┆ null  ┆ null             ┆ null     ┆ null  │\n",
       "│ 2016 ┆ 10    ┆ 22  ┆ 5    ┆ … ┆ null  ┆ null             ┆ null     ┆ null  │\n",
       "│ 2016 ┆ 10    ┆ 22  ┆ 5    ┆ … ┆ null  ┆ null             ┆ null     ┆ null  │\n",
       "│ 2016 ┆ 10    ┆ 22  ┆ 5    ┆ … ┆ null  ┆ null             ┆ null     ┆ null  │\n",
       "└──────┴───────┴─────┴──────┴───┴───────┴──────────────────┴──────────┴───────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainband_joined_w_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "innercore_joined_pd = innercore_joined.to_pandas()\n",
    "rainband_joined_pd = rainband_joined.to_pandas()\n",
    "\n",
    "innercore_joined_w_time = innercore_joined_w_time.to_pandas()\n",
    "rainband_joined_w_time = rainband_joined_w_time.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The null value appears when there is no exact hour match. For example, if filtered_reduced_trackfile has hour 11 but the innercore_count file does not have 11 (only 10:45, 12:15 for example) then it has null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm_code</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>lightining_count</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pressure</th>\n",
       "      <th>knots</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>category</th>\n",
       "      <th>basin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_10_1</td>\n",
       "      <td>2010-06-20 17:30:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>ATL_10_12</td>\n",
       "      <td>2010-09-12 05:30:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>ATL_10_13</td>\n",
       "      <td>2010-09-09 11:30:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>ATL_10_17</td>\n",
       "      <td>2010-10-03 17:30:00</td>\n",
       "      <td>17</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>ATL_10_18</td>\n",
       "      <td>2010-10-08 17:30:00</td>\n",
       "      <td>18</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119638</th>\n",
       "      <td>WPAC_18_3</td>\n",
       "      <td>2018-03-23 05:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122106</th>\n",
       "      <td>WPAC_18_9</td>\n",
       "      <td>2018-06-27 05:30:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123330</th>\n",
       "      <td>WPAC_19_19</td>\n",
       "      <td>2019-09-25 17:30:00</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129149</th>\n",
       "      <td>WPAC_20_22</td>\n",
       "      <td>2020-10-25 05:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129944</th>\n",
       "      <td>WPAC_20_7</td>\n",
       "      <td>2020-08-08 11:30:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        storm_code            time_bin  lightining_count  year  month  day  \\\n",
       "0         ATL_10_1 2010-06-20 17:30:00                 2  2010      6   20   \n",
       "923      ATL_10_12 2010-09-12 05:30:00                19  2010      9   12   \n",
       "1131     ATL_10_13 2010-09-09 11:30:00                 3  2010      9    9   \n",
       "1704     ATL_10_17 2010-10-03 17:30:00                17  2010     10    3   \n",
       "1972     ATL_10_18 2010-10-08 17:30:00                18  2010     10    8   \n",
       "...            ...                 ...               ...   ...    ...  ...   \n",
       "119638   WPAC_18_3 2018-03-23 05:30:00                 1  2018      3   23   \n",
       "122106   WPAC_18_9 2018-06-27 05:30:00                 7  2018      6   27   \n",
       "123330  WPAC_19_19 2019-09-25 17:30:00                12  2019      9   25   \n",
       "129149  WPAC_20_22 2020-10-25 05:30:00                 1  2020     10   25   \n",
       "129944   WPAC_20_7 2020-08-08 11:30:00                 5  2020      8    8   \n",
       "\n",
       "        hour  minute  lat  lon  pressure  knots storm_name  category basin  \n",
       "0         17      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "923        5      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "1131      11      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "1704      17      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "1972      17      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "...      ...     ...  ...  ...       ...    ...        ...       ...   ...  \n",
       "119638     5      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "122106     5      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "123330    17      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "129149     5      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "129944    11      30  NaN  NaN       NaN    NaN       None       NaN  None  \n",
       "\n",
       "[189 rows x 15 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainband_joined_pd.isnull().sum()\n",
    "rainband_joined_pd[rainband_joined_pd.isna().any(axis=1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
